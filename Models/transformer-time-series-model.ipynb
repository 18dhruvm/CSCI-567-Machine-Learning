{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from tqdm. auto import tqdm\n","import torch\n","import torch.autograd as autograd\n","import torch.nn as nn\n","import torch.nn. functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import pytorch_lightning as pl\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","from matplotlib.ticker import MaxNLocator\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from multiprocessing import cpu_count\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n","from pytorch_lightning.loggers import TensorBoardLogger\n","#from pytorch_lightning.metrics.functional import accuracy\n","from sklearn.metrics import classification_report, confusion_matrix\n","import os\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.nn.utils.rnn import pad_sequence\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from multiprocessing import cpu_count\n","import torchmetrics\n","from torchmetrics.functional import accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train = pd.read_csv(\"../Dataset/timeseries.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["columns_to_encode = ['activity', 'up_event', 'down_event', 'text_change']\n","\n","for column in columns_to_encode:\n","    X_train_encoded = pd.get_dummies(X_train[column], prefix=column)\n","    X_train = pd.concat([X_train, X_train_encoded], axis=1)\n","    X_train = X_train.drop(column, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_train = pd.read_csv('/kaggle/input/scores-time-series/train_scores.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["label_encoder=LabelEncoder ()\n","encoded_labels = label_encoder.fit_transform(y_train.score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_train[\"label\"]= encoded_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_train.drop('score', inplace=True, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["FEATURE_COLUMNS = X_train.columns.tolist()[2:]\n","FEATURE_COLUMNS"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["maxi = X_train.id.value_counts().max()\n","maxi"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sequences = []\n","for id, group in X_train.groupby(\"id\"):\n","  sequence_features = group[FEATURE_COLUMNS]\n","  # Number of rows to add with zeros\n","  custom_rows = maxi - sequence_features.shape[0]\n","\n","  # Creating a DataFrame with zeros\n","  zeros_df = pd.DataFrame(0, index=range(custom_rows), columns=sequence_features.columns)\n","  # Appending the DataFrame with zeros to the original DataFrame\n","  sequence_features = pd.concat([sequence_features, zeros_df], ignore_index=True)\n","\n","  label= y_train[y_train.id == id].iloc[0].label\n","  sequences.append((sequence_features, label))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(sequences)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_sequences, test_sequences = train_test_split(sequences, test_size=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class EssayDataset(Dataset):\n","  def __init__ (self, sequences):\n","    self.sequences = sequences\n","\n","  def __len__ (self):\n","    return len(self.sequences)\n","\n","  def __getitem__ (self, idx):\n","    sequence, label = self.sequences [idx]\n","    return dict(\n","      sequence=torch.Tensor(sequence.to_numpy()),\n","      label=torch.tensor(label).long()\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","\n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","\n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for batch in self.dl:\n","            # yield to_device(b, self.device)\n","            yield {key: value.to(self.device) if isinstance(value, torch.Tensor) else value for key, value in batch.items()}\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = get_default_device()\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class EssayDataModule (pl.LightningDataModule):\n","  def __init__(self, train_sequences, test_sequences, batch_size):\n","    super().__init__()\n","    self.train_sequences = train_sequences\n","    self.test_sequences = test_sequences\n","    self.batch_size = batch_size\n","\n","  def setup(self, stage=None):\n","    self.train_dataset = EssayDataset(self.train_sequences)\n","    self.test_dataset = EssayDataset(self. test_sequences)\n","\n","  def train_dataloader (self):\n","    return DataLoader(\n","      self.train_dataset,\n","      batch_size=self.batch_size,\n","      shuffle=True,\n","      num_workers=cpu_count()\n","    )\n","\n","  def val_dataloader (self):\n","    return DataLoader(\n","      self.test_dataset,\n","      batch_size=self.batch_size,\n","      shuffle=False,\n","      num_workers=cpu_count()\n","    )\n","\n","  def test_dataloader(self):\n","    return DataLoader(\n","      self.test_dataset,\n","      batch_size=self.batch_size,\n","      shuffle=False,\n","      num_workers=cpu_count()\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["N_EPOCHS = 50\n","BATCH_SIZE = 8\n","data_module = EssayDataModule(train_sequences, test_sequences, BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class TimeSeriesTransformer(nn.Module):\n","    def __init__(self, input_size, num_classes, d_model=8, nhead=2, num_layers=2):\n","        super(TimeSeriesTransformer, self).__init__()\n","        self.embedding = nn.Linear(input_size, d_model)\n","        self.transformer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n","        self.transformer_encoder = nn.TransformerEncoder(self.transformer, num_layers=num_layers)\n","        self.fc = nn.Linear(d_model, num_classes)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x = x.permute(1, 0, 2)  # Change the sequence length dimension to be the first dimension\n","        x = self.transformer_encoder(x)\n","        x = x.mean(dim=0)  # Aggregate the sequence information\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class TimeSeriesClassifier(pl.LightningModule):\n","    def __init__(self, input_size, num_classes, d_model=8, nhead=2, num_layers=2, learning_rate=1e-3):\n","        super(TimeSeriesClassifier, self).__init__()\n","        self.model = TimeSeriesTransformer(input_size, num_classes, d_model, nhead, num_layers)\n","        self.criterion = nn.CrossEntropyLoss()\n","        self.learning_rate = learning_rate\n","        self.num_classes=num_classes\n","        self.num_layers = num_layers\n","\n","    def forward(self, x, labels = None):\n","        output = self.model(x)\n","        loss = 0\n","        if labels is not None:\n","          loss = self.criterion (output, labels)\n","        return loss, output\n","\n","    def training_step(self, batch, batch_idx):\n","        sequences, labels = batch['sequence'], batch['label']\n","        loss, outputs = self(sequences, labels)\n","        predictions = torch.argmax(outputs, dim=1)\n","        step_accuracy = accuracy(predictions, labels, task='multiclass', num_classes=self.num_classes)\n","\n","        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n","        self.log(\"train_accuracy\", step_accuracy, prog_bar=True, logger=True)\n","        return {\"loss\": loss, \"accuracy\": step_accuracy}\n","\n","    def validation_step(self, batch, batch_idx):\n","        sequences, labels = batch['sequence'], batch['label']\n","        loss, outputs = self(sequences, labels)\n","        predictions = torch.argmax(outputs, dim=1)\n","        step_accuracy = accuracy(predictions, labels, task='multiclass', num_classes=self.num_classes)\n","\n","        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n","        self.log(\"val_accuracy\", step_accuracy, prog_bar=True, logger=True)\n","        return {\"loss\": loss, \"accuracy\": step_accuracy}\n","\n","    def testing_step(self, batch, batch_idx):\n","        sequences, labels = batch['sequence'], batch['label']\n","        loss, outputs = self(sequences, labels)\n","        predictions = torch.argmax(outputs, dim=1)\n","        step_accuracy = accuracy(predictions, labels, task='multiclass', num_classes=self.num_classes)\n","\n","        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n","        self.log(\"test_accuracy\", step_accuracy, prog_bar=True, logger=True)\n","        return {\"loss\": loss, \"accuracy\": step_accuracy}\n","\n","    def configure_optimizers(self):\n","        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n","        return optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = TimeSeriesClassifier(\n","  input_size=len(FEATURE_COLUMNS),\n","  num_classes=len(label_encoder.classes_)\n",").to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%load_ext tensorboard\n","%tensorboard --logdir ./lightning_logs"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["checkpoint_callback = ModelCheckpoint(\n","  dirpath=\"checkpoints\",\n","  filename=\"best-checkpoint\",\n","  save_top_k=1,\n","  verbose=True,\n","  monitor=\"val_loss\",\n","  mode=\"min\"\n",")\n","\n","logger = TensorBoardLogger(\"lightning_logs\", name=\"surface\")\n","\n","trainer = pl.Trainer(\n","  logger=logger,\n","  callbacks=checkpoint_callback,\n","  max_epochs=N_EPOCHS,\n","  devices=1,\n","  accelerator='gpu'\n","\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer.fit(model, data_module)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4051294,"sourceId":7041481,"sourceType":"datasetVersion"},{"datasetId":4051424,"sourceId":7041658,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":4}
