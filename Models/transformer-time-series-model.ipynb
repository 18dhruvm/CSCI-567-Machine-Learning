{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7041481,"sourceType":"datasetVersion","datasetId":4051294},{"sourceId":7041658,"sourceType":"datasetVersion","datasetId":4051424}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/PyTorchLightning/pytorch-lightning\nimport pytorch_lightning as pl\nprint(pl.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm. auto import tqdm\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn. functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport pytorch_lightning as pl\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom matplotlib.ticker import MaxNLocator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom multiprocessing import cpu_count\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\n#from pytorch_lightning.metrics.functional import accuracy\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport os\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.nn.utils.rnn import pad_sequence\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom multiprocessing import cpu_count\nimport torchmetrics\nfrom torchmetrics.functional import accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = pd.read_csv(\"/kaggle/input/data-time-series/dataset_anuranjan.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_to_encode = ['activity', 'up_event', 'down_event', 'text_change']\n\nfor column in columns_to_encode:\n    X_train_encoded = pd.get_dummies(X_train[column], prefix=column)\n    X_train = pd.concat([X_train, X_train_encoded], axis=1)\n    X_train = X_train.drop(column, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = pd.read_csv('/kaggle/input/scores-time-series/train_scores.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder=LabelEncoder ()\nencoded_labels = label_encoder.fit_transform(y_train.score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[\"label\"]= encoded_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.drop('score', inplace=True, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FEATURE_COLUMNS = X_train.columns.tolist()[2:]\nFEATURE_COLUMNS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxi = X_train.id.value_counts().max()\nmaxi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequences = []\nfor id, group in X_train.groupby(\"id\"):\n  sequence_features = group[FEATURE_COLUMNS]\n  # Number of rows to add with zeros\n  custom_rows = maxi - sequence_features.shape[0]\n\n  # Creating a DataFrame with zeros\n  zeros_df = pd.DataFrame(0, index=range(custom_rows), columns=sequence_features.columns)\n  # Appending the DataFrame with zeros to the original DataFrame\n  sequence_features = pd.concat([sequence_features, zeros_df], ignore_index=True)\n\n  label= y_train[y_train.id == id].iloc[0].label\n  sequences.append((sequence_features, label))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(sequences)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sequences, test_sequences = train_test_split(sequences, test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SurfaceDataset(Dataset):\n  def __init__ (self, sequences):\n    self.sequences = sequences\n\n  def __len__ (self):\n    return len(self.sequences)\n\n  def __getitem__ (self, idx):\n    sequence, label = self.sequences [idx]\n    return dict(\n      sequence=torch.Tensor(sequence.to_numpy()),\n      label=torch.tensor(label).long()\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n\ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n\n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for batch in self.dl:\n            # yield to_device(b, self.device)\n            yield {key: value.to(self.device) if isinstance(value, torch.Tensor) else value for key, value in batch.items()}\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SurfaceDataModule (pl.LightningDataModule):\n  def __init__(self, train_sequences, test_sequences, batch_size):\n    super().__init__()\n    self.train_sequences = train_sequences\n    self.test_sequences = test_sequences\n    self.batch_size = batch_size\n\n  def setup(self, stage=None):\n    self.train_dataset = SurfaceDataset(self.train_sequences)\n    self.test_dataset = SurfaceDataset(self. test_sequences)\n\n  def train_dataloader (self):\n    return DataLoader(\n      self.train_dataset,\n      batch_size=self.batch_size,\n      shuffle=True,\n      num_workers=cpu_count()\n    )\n\n  def val_dataloader (self):\n    return DataLoader(\n      self.test_dataset,\n      batch_size=self.batch_size,\n      shuffle=False,\n      num_workers=cpu_count()\n    )\n\n  def test_dataloader(self):\n    return DataLoader(\n      self.test_dataset,\n      batch_size=self.batch_size,\n      shuffle=False,\n      num_workers=cpu_count()\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 50\nBATCH_SIZE = 8\ndata_module = SurfaceDataModule(train_sequences, test_sequences, BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TimeSeriesTransformer(nn.Module):\n    def __init__(self, input_size, num_classes, d_model=8, nhead=2, num_layers=2):\n        super(TimeSeriesTransformer, self).__init__()\n        self.embedding = nn.Linear(input_size, d_model)\n        self.transformer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n        self.transformer_encoder = nn.TransformerEncoder(self.transformer, num_layers=num_layers)\n        self.fc = nn.Linear(d_model, num_classes)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = x.permute(1, 0, 2)  # Change the sequence length dimension to be the first dimension\n        x = self.transformer_encoder(x)\n        x = x.mean(dim=0)  # Aggregate the sequence information\n        x = self.fc(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TimeSeriesClassifier(pl.LightningModule):\n    def __init__(self, input_size, num_classes, d_model=8, nhead=2, num_layers=2, learning_rate=1e-3):\n        super(TimeSeriesClassifier, self).__init__()\n        self.model = TimeSeriesTransformer(input_size, num_classes, d_model, nhead, num_layers)\n        self.criterion = nn.CrossEntropyLoss()\n        self.learning_rate = learning_rate\n        self.num_classes=num_classes\n        self.num_layers = num_layers\n\n    def forward(self, x, labels = None):\n        output = self.model(x)\n        loss = 0\n        if labels is not None:\n          loss = self.criterion (output, labels)\n        return loss, output\n\n    def training_step(self, batch, batch_idx):\n        sequences, labels = batch['sequence'], batch['label']\n        loss, outputs = self(sequences, labels)\n        predictions = torch.argmax(outputs, dim=1)\n        step_accuracy = accuracy(predictions, labels, task='multiclass', num_classes=self.num_classes)\n\n        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n        self.log(\"train_accuracy\", step_accuracy, prog_bar=True, logger=True)\n        return {\"loss\": loss, \"accuracy\": step_accuracy}\n\n    def validation_step(self, batch, batch_idx):\n        sequences, labels = batch['sequence'], batch['label']\n        loss, outputs = self(sequences, labels)\n        predictions = torch.argmax(outputs, dim=1)\n        step_accuracy = accuracy(predictions, labels, task='multiclass', num_classes=self.num_classes)\n\n        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n        self.log(\"val_accuracy\", step_accuracy, prog_bar=True, logger=True)\n        return {\"loss\": loss, \"accuracy\": step_accuracy}\n\n    def testing_step(self, batch, batch_idx):\n        sequences, labels = batch['sequence'], batch['label']\n        loss, outputs = self(sequences, labels)\n        predictions = torch.argmax(outputs, dim=1)\n        step_accuracy = accuracy(predictions, labels, task='multiclass', num_classes=self.num_classes)\n\n        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n        self.log(\"test_accuracy\", step_accuracy, prog_bar=True, logger=True)\n        return {\"loss\": loss, \"accuracy\": step_accuracy}\n\n    def configure_optimizers(self):\n        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n        return optimizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = TimeSeriesClassifier(\n  input_size=len(FEATURE_COLUMNS),\n  num_classes=len(label_encoder.classes_)\n).to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir ./lightning_logs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = ModelCheckpoint(\n  dirpath=\"checkpoints\",\n  filename=\"best-checkpoint\",\n  save_top_k=1,\n  verbose=True,\n  monitor=\"val_loss\",\n  mode=\"min\"\n)\n\nlogger = TensorBoardLogger(\"lightning_logs\", name=\"surface\")\n\ntrainer = pl.Trainer(\n  logger=logger,\n  callbacks=checkpoint_callback,\n  max_epochs=N_EPOCHS,\n  devices=1,\n  accelerator='gpu'\n\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model, data_module)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}